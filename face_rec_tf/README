UNDER CONSTRUCTION:

This demo showcase simple face recognition and pedestrian detection.
It is based on tensorflow pretrained model. In the github, the model
is is not shared but it publicly available.

This repository is not yet complete. It has some missing video and
images that are needed to showcase the demo.

The script uses OO concepts and it defines bunch of baseclass and
inherited class to organize the code. The class definitions all go in one file.
The demo script imports the class definition file which reduces scripting work
in the demo example. Also this OO design will be beneficial when we plan
to provision for scaling - supporting multiple cameras and therefore introducing
multiple threads as opposed to running everything in one single thread.

The machine learning and pedestrian detection scripting is re organized
to handle many different example scenarios in a compact way. The main
examples are:

    (i)   face training
    (ii)  face classification
    (iii) pedestrian detecion

With the different input feeds that can be used and the different mechanism
to provide output feeds the combinations are many.For each application
following are the input feed mechanism:

    (i)  camera - AXIS and AMCREST camera support so far
    (ii) video clip

For each application following are the output feed mechanism:
    (i)   video clip
    (ii)  file - generated still pictures are saved in files
    (iii) streaming - via webserver

Launching help for the application script
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The consolidated script is ml_app.py. Below it is shown how this
script can be invoked with different kinds of options.

$python ml_app.py --help
usage: ml_app.py [-h] (--body | --classify | --train name)
                 (--camera ip make | --video file) --out sink

optional arguments:
  -h, --help        show this help message and exit
  --body            Run body detection app
  --classify        Run face recoginition
  --train name      Run training for face recognition for name
  --camera ip make  The IP address and make = [AXIS|AMCREST]
  --video file      The classification <file> : video or still
  --out sink        sink could be ["stream" | "video" | "pic"]


Example commands
^^^^^^^^^^^^^^^^
Example 1 : Classification - input:video output:video
=======================================================
$python ml_app --classify --video media_files/vtest.avi --out video

Example 2 : Classification - input:camera output:video
=======================================================
$python ml_app --classify --camera 192.168.0.202 AMCREST_--out video


Example 3 : Classification - input:camera output:stream
=======================================================
$python ml_app --classify --camera 192.168.0.202 AMCREST_--out stream

Example 4 : Classification - input:camera output:pic
=======================================================
$python ml_app --classify --camera 192.168.0.202 AMCREST_--out pic


In a similar fashion --train and --body example commands can be construted.

Files:
^^^^^^
1. ml_app.py : main application script
2. face.py : common classes for face recognition training and classification
3. face_tr.py : classes for training face
4. face_cl.py : classes for classifying face
5. ped_detect.py : classes for pedestrian detection
6. camera_in.py : classes that define methods for camera access
7. video_in.py : classes that defined methods for video access
8. video_out.py : classes for sending video to output
9. stream_out.py : classes for output streaming (borrowed from open source)
10. media_files/ : this sub directory contains all video files used by app

At Runtime following subdirectory and files get created. The subdirectory
is created for training or classification or pedestrian detection when
'--out pic' option is chosen. This means user is interested in saving
the still pictures while the application is being executed or processed.
All the following sub directories can be removed with impacting any
kind of functionalities provided by application script.

11. delete_[random_string] : this directory is created by classification
12. recog_ped_camera_[random_string] : saved pedestrian pictures
12. recog_ped_video_[random_string] : saved pedestrian pictures
12. recog_train_camera_[random_string] : saved pedestrian pictures
12. recog_train_video_[random_string] : saved pedestrian pictures
12. recog_classify_camera_[random_string] : saved pedestrian pictures
12. recog_classify_video_[random_string] : saved pedestrian pictures


APPENDIX
Hardware used
^^^^^^^^^^^^^
AXIS M1034-W Network Camera
Ubuntu 16.04 running on Dell Optiplex 790
The Axis Network camera is connected with Ethernet cable to the Dell Optiplex
(running Ubuntu 16.04) machine's e1000 based network port.

2.1 Hardware specification of Dell Optiplex
--------------------------------------------
Processor Information : Core i7 @ 3.40GHz
Cache Information : L1/256kB/WB
Cache Information : L2/1024kB
Cache Information : L3/8192kB
Physical Memory Array : 32GB/#devices=4
Each Memory Device 1 : DDR3/4GB/1333MHz/DIMM
NIC : Intel Corporation PRO/1000 PT Server Adapter; e1000e driver

3. Software
^^^^^^^^^^^^
3.1 Tensorflow 1.3.0
Detailed description of how to install Tensorflow is provided here:
https://www.tensorflow.org/install/
Following the instructions in the above link you can either build
tensorflow from source or you can simply install it. Here the tensorflow
was built from source.

3.2 facenet git repository
---------------------------
In order to run the demo the following git repository needs to be cloned:
https://github.com/davidsandberg/facenet.git

3.3 Additional python packages used by demo
--------------------------------------------
In addition to using the facenet python distribution, few other
python packages need to be installed. The 'pip install...' or 'sudo pip install...'
can be used once it is known which packages need to be installed.
This is the list of all the modules used by the demo:

import tensorflow as tf
import numpy as np
import argparse
import facenet
import os
import sys
import math
import pickle

import cv2
import pdb
import shutil
import requests
import time
import datetime

from sklearn.svm import SVC

Ensure that all of them are installed. Otherwise when you run the demo
the script would fail due to lack of finding the dependent module/modules.

4. Setting up the demo
^^^^^^^^^^^^^^^^^^^^^^
4.1 Connect hardware
---------------------
Connect the camera with an Ethernet cable to your compute machine.
The default IP address for the camera is 192.168.1.121

4.2 Launch the IP camera management GUI
---------------------------------------
Specifically, reduce the resolution of the video streaming
window size. Look at 'Basic Setup->Video Stream' and select
640x800 resolution. The default 1280x480 resolution is too high
and gives the frame processing of video streaming a sloppy look.

4.3 Setup environment variables
--------------------------------
For the purposes of discussion, it is assumed that the following
environment variables are defined:

$FACENET=>directory where the facenet git repository is cloned
$FACERECOGNITION=>directory where face recognition repository is cloned
$PYTHONPATH=$FACENET/src

